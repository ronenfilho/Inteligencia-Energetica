from __future__ import annotations

import pendulum
import requests
import json
from datetime import datetime, timedelta
from airflow.models.dag import DAG
from airflow.decorators import task
from airflow.models import Variable
from airflow.operators.python import get_current_context

dag = DAG(
    dag_id='aaa_GERACAO_USINA_2_v3',
    schedule=None,  # ExecuÃ§Ã£o Ãºnica, nÃ£o recorrente
    catchup=False,
    tags=['airbyte', 'sources', '2025', 'energy', 'geracao', 'one-time'],
    description='Criar sources e connections no Airbyte para GERACAO_USINA_2 - v2 execuÃ§Ã£o Ãºnica',
    default_args={
        'owner': 'data_team',
        'depends_on_past': False,
        'email_on_failure': False,
        'email_on_retry': False,
        'retries': 2,
        'retry_delay': pendulum.duration(minutes=2),
    },
    params={
        "start_date": "2022-01-01",  # Data de inÃ­cio da captura (formato YYYY-MM-DD) - 2022+ para dados mensais
        "end_date": "auto",          # "auto" para atÃ© mÃªs atual (exclui futuros) ou YYYY-MM-DD para data especÃ­fica
        "force_recreate": False,     # Se True, recria sources mesmo se jÃ¡ existirem
        "trigger_sync": True         # Se True, inicia sincronizaÃ§Ã£o automÃ¡tica apÃ³s criar connections
    }
)

def get_access_token():
    """Gera um novo access token usando client credentials"""
    client_id = Variable.get("AIRBYTE_CLIENT_ID")
    client_secret = Variable.get("AIRBYTE_CLIENT_SECRET")
    
    response = requests.post(
        "https://api.airbyte.com/v1/applications/token",
        headers={"Content-Type": "application/json"},
        json={
            "client_id": client_id,
            "client_secret": client_secret
        }
    )
    
    if response.status_code != 200:
        raise Exception(f"Erro ao obter access token: {response.status_code} - {response.text}")
    
    return response.json()["access_token"]

def make_api_request(method, endpoint, data=None):
    """Faz uma requisiÃ§Ã£o Ã  API do Airbyte com token refresh automÃ¡tico"""
    access_token = get_access_token()
    base_url = "https://api.airbyte.com/v1"
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    url = f"{base_url}{endpoint}"
    
    # Log da requisiÃ§Ã£o sendo feita
    print(f"ğŸŒ API Request: {method} {url}")
    if data and method.upper() == "POST":
        print(f"ğŸ“„ Request Body: {json.dumps(data, indent=2)}")
    
    if method.upper() == "GET":
        response = requests.get(url, headers=headers)
    elif method.upper() == "POST":
        response = requests.post(url, headers=headers, json=data)
    elif method.upper() == "DELETE":
        response = requests.delete(url, headers=headers)
    else:
        raise ValueError(f"MÃ©todo HTTP nÃ£o suportado: {method}")
    
    return response

def check_connection_exists(connection_name, workspace_id):
    """Verifica se uma connection com o nome especificado jÃ¡ existe"""
    try:
        response = make_api_request("GET", f"/workspaces/{workspace_id}/connections")
        
        if response.status_code == 200:
            connections = response.json().get("data", [])
            for connection in connections:
                if connection.get("name") == connection_name:
                    return connection.get("connectionId")
        
        return None
        
    except Exception as e:
        print(f"âŒ Erro ao verificar connection existente: {str(e)}")
        return None

def delete_conflicting_connections(stream_name, workspace_id):
    """Deleta connections que possuem streams conflitantes"""
    deleted_count = 0
    
    try:
        # Listar todas as connections do workspace
        response = make_api_request("GET", f"/workspaces/{workspace_id}/connections")
        
        if response.status_code != 200:
            print(f"âŒ Erro ao listar connections: {response.status_code}")
            return deleted_count
        
        connections = response.json().get("data", [])
        print(f"ğŸ” Verificando {len(connections)} connections para conflitos com stream: {stream_name}")
        
        for connection in connections:
            connection_id = connection.get("connectionId")
            connection_name = connection.get("name", "Unknown")
            
            try:
                # Obter detalhes da connection incluindo streams
                detail_response = make_api_request("GET", f"/connections/{connection_id}")
                
                if detail_response.status_code == 200:
                    connection_detail = detail_response.json()
                    
                    # Verificar se esta connection tem o stream conflitante
                    streams = connection_detail.get("syncCatalog", {}).get("streams", [])
                    
                    has_conflicting_stream = False
                    for stream in streams:
                        stream_config = stream.get("config", {})
                        if stream_config.get("selected", False):
                            stream_stream = stream.get("stream", {})
                            current_stream_name = stream_stream.get("name", "")
                            
                            if current_stream_name == stream_name:
                                has_conflicting_stream = True
                                break
                    
                    if has_conflicting_stream:
                        print(f"ğŸ—‘ï¸ Deletando connection conflitante: {connection_name} ({connection_id})")
                        
                        # Deletar a connection
                        delete_response = make_api_request("DELETE", f"/connections/{connection_id}")
                        
                        if delete_response.status_code in [200, 204]:
                            print(f"âœ… Connection deletada: {connection_name}")
                            deleted_count += 1
                        else:
                            print(f"âŒ Erro ao deletar connection {connection_name}: {delete_response.status_code}")
                    
                else:
                    print(f"âš ï¸ NÃ£o foi possÃ­vel obter detalhes da connection {connection_id}")
                    
            except Exception as e:
                print(f"âŒ Erro ao processar connection {connection_id}: {str(e)}")
                continue
        
        print(f"ğŸ¯ Total de connections conflitantes deletadas: {deleted_count}")
        return deleted_count
        
    except Exception as e:
        print(f"âŒ Erro ao deletar connections conflitantes: {str(e)}")
        return deleted_count

def generate_optimized_period_list(start_date_str, end_date_str):
    """Gera lista otimizada de perÃ­odos baseada na regra de agrupamento da ONS"""
    from datetime import datetime
    
    # Parse das datas
    start_date = datetime.strptime(start_date_str, "%Y-%m-%d")
    
    if end_date_str == "auto":
        # Usar data atual, mas limitar ao mÃªs atual (nÃ£o incluir meses futuros)
        end_date = datetime.now()
        print(f"ğŸ“… Data atual detectada: {end_date.strftime('%Y-%m-%d')}")
    else:
        end_date = datetime.strptime(end_date_str, "%Y-%m-%d")
    
    periods = []
    
    # TraduÃ§Ã£o dos meses para portuguÃªs
    month_translations = {
        "January": "Janeiro", "February": "Fevereiro", "March": "MarÃ§o",
        "April": "Abril", "May": "Maio", "June": "Junho",
        "July": "Julho", "August": "Agosto", "September": "Setembro",
        "October": "Outubro", "November": "Novembro", "December": "Dezembro"
    }
    
    # 1. PROCESSAR ANOS 2000-2021 (arquivo anual) - apenas um source por ano
    print("ğŸ“Š Analisando perÃ­odo 2000-2021 (arquivos anuais)...")
    start_year = max(2000, start_date.year)  # NÃ£o processar antes de 2000
    end_year_legacy = min(2021, end_date.year)  # NÃ£o processar depois de 2021 para arquivos anuais
    
    for year in range(start_year, end_year_legacy + 1):
        # Para arquivos anuais, usar Janeiro como representante (month_code serÃ¡ usado apenas no nome)
        year_code = f"{year}-01"  # Usar Janeiro como padrÃ£o
        year_name = f"Ano {year}"
        periods.append((year_code, year_name, "annual"))
    
    # 2. PROCESSAR ANOS 2022+ (arquivo mensal) - um source por mÃªs
    print("ğŸ“Š Analisando perÃ­odo 2022+ (arquivos mensais)...")
    if end_date.year >= 2022:
        # ComeÃ§ar em 2022 ou na data de inÃ­cio, o que for maior
        monthly_start = datetime(max(2022, start_date.year), 1, 1)
        if start_date.year >= 2022:
            monthly_start = start_date.replace(day=1)
        
        current = monthly_start
        current_month = datetime.now().replace(day=1)  # MÃªs atual para comparaÃ§Ã£o
        
        while current <= end_date:
            # Se for "auto", nÃ£o incluir meses futuros (posteriores ao mÃªs atual)
            if end_date_str == "auto" and current > current_month:
                print(f"â¹ï¸ Parando em {current.strftime('%Y-%m')} - mÃªs futuro nÃ£o incluÃ­do")
                break
                
            month_code = current.strftime("%Y-%m")
            month_name = current.strftime("%B %Y")
            
            # Aplicar traduÃ§Ã£o
            for en, pt in month_translations.items():
                month_name = month_name.replace(en, pt)
            
            periods.append((month_code, month_name, "monthly"))
            
            # AvanÃ§ar para o prÃ³ximo mÃªs
            if current.month == 12:
                current = current.replace(year=current.year + 1, month=1)
            else:
                current = current.replace(month=current.month + 1)
    
    # Log informativo dos perÃ­odos que serÃ£o processados
    if periods:
        annual_count = len([p for p in periods if p[2] == "annual"])
        monthly_count = len([p for p in periods if p[2] == "monthly"])
        
        print(f"ğŸ“‹ PerÃ­odos otimizados que serÃ£o processados:")
        print(f"   ğŸ“… Arquivos anuais (2000-2021): {annual_count} sources")
        print(f"   ğŸ“… Arquivos mensais (2022+): {monthly_count} sources")
        print(f"   ğŸ“Š Total otimizado: {len(periods)} sources (vs {len(periods) if len(periods) < 50 else '300+'} sources no mÃ©todo anterior)")
        
        if end_date_str == "auto":
            print(f"ğŸš« Meses futuros excluÃ­dos automaticamente (data atual: {datetime.now().strftime('%Y-%m')})")
    
    return periods

def check_source_exists(source_name, workspace_id):
    """Verifica se um source jÃ¡ existe no workspace"""
    try:
        response = make_api_request("GET", f"/workspaces/{workspace_id}/sources")
        
        if response.status_code == 200:
            sources = response.json().get("data", [])
            for source in sources:
                if source.get("name") == source_name:
                    return source.get("sourceId")
        return None
    except Exception as e:
        print(f"âŒ Erro ao verificar sources existentes: {str(e)}")
        return None

@task
def explore_api_structure_task():
    """Explora a estrutura da API do Airbyte para entender as chaves e endpoints disponÃ­veis"""
    print("ğŸ” EXPLORANDO ESTRUTURA DA API DO AIRBYTE")
    print("=" * 60)
    
    # Usar as variÃ¡veis que funcionam no v7
    try:
        workspace_id = Variable.get("airbyte_workspace_id")
        print(f"âœ… Workspace ID (v7): {workspace_id}")
    except:
        workspace_id = Variable.get("AIRBYTE_WORKSPACE_ID")
        print(f"âœ… Workspace ID (maiÃºsculo): {workspace_id}")
    
    results = {}
    
    # 1. TESTAR ENDPOINTS DE LISTAGEM
    print("\nğŸŒ TESTANDO ENDPOINTS DE LISTAGEM:")
    print("-" * 40)
    
    endpoints_to_test = [
        ("/workspaces", "Listar todos os workspaces"),
        (f"/workspaces/{workspace_id}", "Detalhes do workspace"),
        (f"/workspaces/{workspace_id}/sources", "Sources do workspace"),
        (f"/workspaces/{workspace_id}/destinations", "Destinations do workspace"),
        (f"/workspaces/{workspace_id}/connections", "Connections do workspace"),
        ("/source-definitions", "DefiniÃ§Ãµes de sources disponÃ­veis"),
        ("/destination-definitions", "DefiniÃ§Ãµes de destinations disponÃ­veis")
    ]
    
    for endpoint, description in endpoints_to_test:
        try:
            print(f"ğŸ”„ Testando: {description}")
            print(f"   Endpoint: GET {endpoint}")
            
            response = make_api_request("GET", endpoint)
            
            if response.status_code == 200:
                data = response.json()
                print(f"   âœ… Sucesso ({response.status_code})")
                
                # Analisar estrutura da resposta
                if isinstance(data, dict):
                    if "data" in data:
                        items_count = len(data["data"]) if isinstance(data["data"], list) else "objeto"
                        print(f"   ï¿½ Itens encontrados: {items_count}")
                        
                        # Se Ã© uma lista, mostrar as chaves do primeiro item
                        if isinstance(data["data"], list) and len(data["data"]) > 0:
                            first_item = data["data"][0]
                            if isinstance(first_item, dict):
                                keys = list(first_item.keys())
                                print(f"   ğŸ”‘ Chaves principais: {', '.join(keys[:5])}{'...' if len(keys) > 5 else ''}")
                                
                                # Guardar resultado para anÃ¡lise
                                results[description] = {
                                    "endpoint": endpoint,
                                    "status": response.status_code,
                                    "count": len(data["data"]),
                                    "sample_keys": keys,
                                    "sample_item": first_item
                                }
                    else:
                        keys = list(data.keys())
                        print(f"   ğŸ”‘ Chaves da resposta: {', '.join(keys[:5])}{'...' if len(keys) > 5 else ''}")
                        results[description] = {
                            "endpoint": endpoint,
                            "status": response.status_code,
                            "keys": keys,
                            "data": data
                        }
                
            elif response.status_code == 403:
                print(f"   âŒ Forbidden ({response.status_code}) - Sem permissÃ£o")
                results[description] = {"endpoint": endpoint, "status": response.status_code, "error": "Forbidden"}
                
            elif response.status_code == 404:
                print(f"   âš ï¸ Not Found ({response.status_code}) - Endpoint nÃ£o existe")
                results[description] = {"endpoint": endpoint, "status": response.status_code, "error": "Not Found"}
                
            else:
                print(f"   âŒ Erro ({response.status_code}): {response.text[:100]}...")
                results[description] = {"endpoint": endpoint, "status": response.status_code, "error": response.text[:200]}
                
        except Exception as e:
            print(f"   ğŸ’¥ ExceÃ§Ã£o: {str(e)}")
            results[description] = {"endpoint": endpoint, "error": str(e)}
        
        print()
    
    # 2. ANALISAR SOURCES EXISTENTES EM DETALHES
    print("\nğŸ¯ ANÃLISE DETALHADA DE SOURCES:")
    print("-" * 40)
    
    try:
        sources_response = make_api_request("GET", f"/workspaces/{workspace_id}/sources")
        if sources_response.status_code == 200:
            sources_data = sources_response.json()
            sources = sources_data.get("data", [])
            
            print(f"ğŸ“Š Total de sources encontrados: {len(sources)}")
            
            if sources:
                print("\nğŸ” ESTRUTURA DE UM SOURCE:")
                sample_source = sources[0]
                for key, value in sample_source.items():
                    value_preview = str(value)[:50] + "..." if len(str(value)) > 50 else str(value)
                    print(f"   {key}: {value_preview}")
                
                # Procurar sources que comeÃ§am com GERACAO_USINA
                geracao_sources = [s for s in sources if s.get("name", "").startswith("GERACAO_USINA")]
                print(f"\nğŸ¯ Sources GERACAO_USINA encontrados: {len(geracao_sources)}")
                
                for source in geracao_sources[:3]:  # Mostrar apenas os 3 primeiros
                    print(f"   ğŸ“ {source.get('name', 'N/A')}")
                    print(f"      ID: {source.get('sourceId', 'N/A')}")
                    print(f"      Tipo: {source.get('sourceType', 'N/A')}")
        else:
            print(f"âŒ Erro ao listar sources: {sources_response.status_code}")
            
    except Exception as e:
        print(f"ğŸ’¥ Erro ao analisar sources: {str(e)}")
    
    # 3. TESTAR DEFINIÃ‡Ã•ES DE SOURCES
    print("\nğŸ§© DEFINIÃ‡Ã•ES DE SOURCES DISPONÃVEIS:")
    print("-" * 40)
    
    try:
        definitions_response = make_api_request("GET", "/source-definitions")
        if definitions_response.status_code == 200:
            definitions_data = definitions_response.json()
            definitions = definitions_data.get("data", [])
            
            print(f"ğŸ“Š Total de definiÃ§Ãµes: {len(definitions)}")
            
            # Procurar definiÃ§Ãµes relacionadas a HTTP/File
            file_definitions = [d for d in definitions if "file" in d.get("name", "").lower() or "http" in d.get("name", "").lower()]
            
            print(f"\nğŸ—‚ï¸ DefiniÃ§Ãµes File/HTTP encontradas: {len(file_definitions)}")
            for defn in file_definitions[:5]:  # Mostrar apenas as 5 primeiras
                print(f"   ğŸ“ {defn.get('name', 'N/A')}")
                print(f"      ID: {defn.get('sourceDefinitionId', 'N/A')}")
                print(f"      VersÃ£o: {defn.get('dockerImageTag', 'N/A')}")
                
        else:
            print(f"âŒ Erro ao listar definiÃ§Ãµes: {definitions_response.status_code}")
            
    except Exception as e:
        print(f"ğŸ’¥ Erro ao analisar definiÃ§Ãµes: {str(e)}")
    
    print("\n" + "=" * 60)
    print("âœ… EXPLORAÃ‡ÃƒO DA API CONCLUÃDA")
    
    return results

@task
def create_sources_task():
    """Criar sources para o perÃ­odo configurado"""
    context = get_current_context()
    params = context['params']
    
    # Obter parÃ¢metros da execuÃ§Ã£o
    start_date = params.get('start_date', '2025-01-01')
    end_date = params.get('end_date', 'auto')
    force_recreate = params.get('force_recreate', False)
    
    print(f"ğŸ—“ï¸ PerÃ­odo de captura: {start_date} atÃ© {end_date}")
    print(f"ğŸ”„ Recriar sources existentes: {force_recreate}")
    
    workspace_id = Variable.get("AIRBYTE_WORKSPACE_ID")
    
    # Usar definitionId da variÃ¡vel ou valor padrÃ£o
    try:
        definition_id = Variable.get("airbyte_source_definition_id")
        print(f"ğŸ“‹ Usando definitionId da variÃ¡vel: {definition_id}")
    except Exception:
        definition_id = "778daa7c-feaf-4db6-96f3-70fd645acc77"
        print(f"ğŸ“‹ Usando definitionId padrÃ£o: {definition_id}")
    
    # Gerar lista otimizada de perÃ­odos
    periods = generate_optimized_period_list(start_date, end_date)
    sources_created = []
    
    print(f"ğŸ—ï¸ Iniciando criaÃ§Ã£o de {len(periods)} sources...")
    print(f"ğŸ“ Workspace ID: {workspace_id}")
    print(f"ğŸ”§ Definition ID: {definition_id}")
    
    for month_code, month_name, period_type in periods:
        # NomeaÃ§Ã£o inteligente baseada no tipo de perÃ­odo
        if period_type == "annual":
            year = int(month_code.split("-")[0])
            source_name = f"GERACAO_USINA_2_{year}_ANUAL"
            dataset_name = f"GERACAO_USINA_2_{year}"
        else:  # monthly
            source_name = f"GERACAO_USINA_2_{month_code}"
            dataset_name = f"GERACAO_USINA_2_{month_code}"
        
        print(f"ğŸ”„ Processando source para {month_name} ({month_code}) - Tipo: {period_type}")
        
        # Verificar se o source jÃ¡ existe
        existing_source_id = check_source_exists(source_name, workspace_id)
        
        if existing_source_id and not force_recreate:
            print(f"â­ï¸ Source jÃ¡ existe para {month_name}: {existing_source_id}")
            sources_created.append({
                "month": month_code,
                "name": month_name,
                "source_id": existing_source_id,
                "status": "existing",
                "period_type": period_type
            })
            continue
        elif existing_source_id and force_recreate:
            print(f"ğŸ—‘ï¸ Deletando source existente para recriar: {existing_source_id}")
            try:
                delete_response = make_api_request("DELETE", f"/sources/{existing_source_id}")
                if delete_response.status_code == 204:
                    print(f"âœ… Source deletado com sucesso")
                else:
                    print(f"âš ï¸ NÃ£o foi possÃ­vel deletar source: {delete_response.status_code}")
            except Exception as e:
                print(f"âš ï¸ Erro ao deletar source: {str(e)}")
        
        # URL do arquivo CSV no S3 da ONS - GERACAO_USINA_2
        year = int(month_code.split("-")[0])
        
        if period_type == "annual":
            # Para anos 2000-2021: formato GERACAO_USINA-2_2020.csv (arquivo anual)
            s3_url = f"https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/geracao_usina_2_ho/GERACAO_USINA-2_{year}.csv"
            print(f"ğŸ”— URL S3 (arquivo anual): {s3_url}")
        else:  # monthly
            # Para anos 2022+: formato GERACAO_USINA-2_2025_09.csv (arquivo mensal)
            year_month = month_code.replace("-", "_")  # Converter 2025-01 para 2025_01
            s3_url = f"https://ons-aws-prod-opendata.s3.amazonaws.com/dataset/geracao_usina_2_ho/GERACAO_USINA-2_{year_month}.csv"
            print(f"ğŸ”— URL S3 (arquivo mensal): {s3_url}")
        
        source_data = {
            "name": source_name,
            "workspaceId": workspace_id,
            "definitionId": definition_id,
            "configuration": {
                "dataset_name": dataset_name,
                "format": "csv",
                "url": s3_url,
                "provider": {
                    "storage": "HTTPS",
                    "user_agent": False
                },
                "reader_options": "{ \"delimiter\": \";\" }"
            }
        }
        
        try:
            response = make_api_request("POST", "/sources", source_data)
            
            if response.status_code == 200:
                source_info = response.json()
                source_id = source_info.get("sourceId")
                print(f"âœ… Source criado com sucesso para {month_name}: {source_id}")
                sources_created.append({
                    "month": month_code,
                    "name": month_name,
                    "source_id": source_id,
                    "status": "created",
                    "period_type": period_type
                })
            else:
                print(f"âŒ Erro ao criar source para {month_name}: {response.status_code}")
                print(f"Resposta: {response.text}")
                
        except Exception as e:
            print(f"âŒ ExceÃ§Ã£o ao criar source para {month_name}: {str(e)}")
    
    print(f"\nğŸ“Š Resumo: {len(sources_created)} sources processados")
    
    # EstatÃ­sticas por status
    created_count = len([s for s in sources_created if s.get('status') == 'created'])
    existing_count = len([s for s in sources_created if s.get('status') == 'existing'])
    
    # EstatÃ­sticas por tipo de perÃ­odo
    annual_count = len([s for s in sources_created if s.get('period_type') == 'annual'])
    monthly_count = len([s for s in sources_created if s.get('period_type') == 'monthly'])
    
    print(f"ğŸ†• Criados: {created_count}")
    print(f"ğŸ“‹ JÃ¡ existiam: {existing_count}")
    print(f"ğŸ“… Arquivos anuais (2000-2021): {annual_count}")
    print(f"ğŸ“… Arquivos mensais (2022+): {monthly_count}")
    print(f"ğŸ¯ OtimizaÃ§Ã£o aplicada: Evitou criaÃ§Ã£o de sources duplicados para arquivos anuais")
    
    return sources_created

@task
def create_connections_task(sources_created):
    """Criar connections para os sources criados"""
    if not sources_created:
        print("âŒ Nenhum source foi processado na etapa anterior")
        return []
    
    # Debug: Verificar quais variÃ¡veis existem
    print("ğŸ” Verificando variÃ¡veis disponÃ­veis...")
    
    variables_to_check = [
        "airbyte_workspace_id",
        "airbyte_destination_id_snowflake", 
        "AIRBYTE_WORKSPACE_ID",
        "AIRBYTE_DESTINATION_ID"
    ]
    
    for var_name in variables_to_check:
        try:
            value = Variable.get(var_name)
            print(f"   âœ… {var_name}: {value}")
        except:
            print(f"   âŒ {var_name}: nÃ£o encontrada")
    
    # Usar as mesmas variÃ¡veis do v7 que funciona
    workspace_id = Variable.get("airbyte_workspace_id")
    destination_id = Variable.get("airbyte_destination_id_snowflake")
    print("ğŸ“‹ Usando variÃ¡veis no formato v7 (que funciona): airbyte_workspace_id, airbyte_destination_id_snowflake")
    
    connections_created = []
    
    print(f"ğŸ”— Iniciando criaÃ§Ã£o de connections...")
    print(f"ğŸ“ Workspace ID: {workspace_id}")
    print(f"ğŸ“ Destination ID: {destination_id}")
    
    # Verificar se os IDs sÃ£o vÃ¡lidos
    if not workspace_id or not destination_id:
        print("âŒ VariÃ¡veis de workspace_id ou destination_id nÃ£o configuradas!")
        print("ğŸ“‹ VariÃ¡veis necessÃ¡rias:")
        print("   Formato v7: airbyte_workspace_id, airbyte_destination_id_snowflake")
        print("   OU formato maiÃºsculo: AIRBYTE_WORKSPACE_ID, AIRBYTE_DESTINATION_ID")
        return []
    
    # Validar formato dos IDs (devem ser UUIDs)
    import re
    uuid_pattern = r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$'
    
    if not re.match(uuid_pattern, workspace_id, re.IGNORECASE):
        print(f"âš ï¸ Workspace ID nÃ£o parece ser um UUID vÃ¡lido: {workspace_id}")
    else:
        print(f"âœ… Workspace ID formato vÃ¡lido")
        
    if not re.match(uuid_pattern, destination_id, re.IGNORECASE):
        print(f"âš ï¸ Destination ID nÃ£o parece ser um UUID vÃ¡lido: {destination_id}")
    else:
        print(f"âœ… Destination ID formato vÃ¡lido")
    
    # Tentar validar se o workspace e destination existem
    print("ğŸ” Validando se workspace e destination existem...")
    
    try:
        # Verificar workspace
        workspace_response = make_api_request("GET", f"/workspaces/{workspace_id}")
        if workspace_response.status_code == 200:
            print("âœ… Workspace existe e Ã© acessÃ­vel")
        else:
            print(f"âŒ Erro ao acessar workspace: {workspace_response.status_code}")
            
        # Listar todos os destinations disponÃ­veis no workspace
        print("ğŸ” Listando destinations disponÃ­veis no workspace...")
        destinations_response = make_api_request("GET", f"/workspaces/{workspace_id}/destinations")
        
        if destinations_response.status_code == 200:
            destinations = destinations_response.json().get("data", [])
            print(f"ğŸ“‹ Encontrados {len(destinations)} destinations no workspace:")
            
            snowflake_destinations = []
            for dest in destinations:
                dest_id = dest.get("destinationId", "N/A")
                dest_name = dest.get("name", "Sem nome")
                dest_type = dest.get("destinationType", "N/A")
                
                print(f"   ğŸ¯ {dest_name}")
                print(f"      ID: {dest_id}")
                print(f"      Tipo: {dest_type}")
                
                if "snowflake" in dest_type.lower():
                    snowflake_destinations.append({
                        "id": dest_id,
                        "name": dest_name,
                        "type": dest_type
                    })
            
            if snowflake_destinations:
                print(f"\nâ„ï¸ Destinations Snowflake encontrados: {len(snowflake_destinations)}")
                for sf_dest in snowflake_destinations:
                    print(f"   ğŸ“ Use este ID: {sf_dest['id']}")
                    print(f"      Nome: {sf_dest['name']}")
                    
                # Se hÃ¡ destinations Snowflake, sugerir usar o primeiro
                if len(snowflake_destinations) == 1:
                    correct_dest_id = snowflake_destinations[0]['id']
                    print(f"\nğŸ’¡ SUGESTÃƒO: Configure a variÃ¡vel com o ID correto:")
                    print(f"   AIRBYTE_DESTINATION_ID = {correct_dest_id}")
                    
                    # Tentar usar o ID correto automaticamente
                    print(f"ğŸ”„ Tentando usar destination correto automaticamente...")
                    destination_id = correct_dest_id
                    
        else:
            print(f"âŒ Erro ao listar destinations: {destinations_response.status_code}")
            
        # Verificar destination especÃ­fico
        destination_response = make_api_request("GET", f"/destinations/{destination_id}")
        if destination_response.status_code == 200:
            dest_info = destination_response.json()
            print(f"âœ… Destination existe: {dest_info.get('name', 'sem nome')}")
        else:
            print(f"âŒ Erro ao acessar destination: {destination_response.status_code}")
            if destination_response.status_code == 403:
                print("   PossÃ­vel problema: destination_id incorreto ou sem permissÃ£o")
            elif destination_response.status_code == 404:
                print("   PossÃ­vel problema: destination_id nÃ£o existe")
                
    except Exception as e:
        print(f"âš ï¸ Erro na validaÃ§Ã£o: {e}")
    
    for source_info in sources_created:
        source_id = source_info["source_id"]
        month_name = source_info["name"]
        month_code = source_info["month"]
        source_status = source_info.get("status", "unknown")
        
        connection_name = f"Connection_GERACAO_USINA_2_{month_code}"
        stream_name = f"GERACAO_USINA_2_{month_code}"
        
        print(f"ğŸ”„ Processando connection para {month_name} ({source_id}) - Status: {source_status}")
        
        # Verificar se connection jÃ¡ existe
        existing_connection_id = check_connection_exists(connection_name, workspace_id)
        
        if existing_connection_id:
            print(f"â­ï¸ Connection jÃ¡ existe para {month_name}: {existing_connection_id}")
            connections_created.append({
                "month": month_code,
                "name": month_name,
                "source_id": source_id,
                "connection_id": existing_connection_id,
                "schedule": "existing"
            })
            continue
        
        # ConfiguraÃ§Ã£o da connection para execuÃ§Ã£o manual (sem agendamento recorrente)
        connection_data = {
            "name": connection_name,
            "sourceId": source_id,
            "destinationId": destination_id,
            "syncMode": "full_refresh",
            "schedule": {
                "scheduleType": "manual"
            },
            "status": "active"
        }
        
        # Tentar criar connection - apenas uma tentativa
        print(f"ğŸ”„ Criando connection para {month_name}...")
        
        try:
            response = make_api_request("POST", "/connections", connection_data)
            
            if response.status_code == 200:
                connection_info = response.json()
                connection_id = connection_info.get("connectionId")
                print(f"âœ… Connection criada para {month_name}: {connection_id}")
                connections_created.append({
                    "month": month_code,
                    "name": month_name,
                    "source_id": source_id,
                    "connection_id": connection_id,
                    "schedule": "manual"
                })
                
            else:
                print(f"âŒ Erro ao criar connection para {month_name}: {response.status_code}")
                print(f"ğŸ“„ Resposta completa: {response.text}")
                
                # Debug adicional para erro 403
                if response.status_code == 403:
                    print("ğŸ” ANÃLISE DO ERRO 403:")
                    print(f"   Source ID: {source_id}")
                    print(f"   Destination ID: {destination_id}")
                    print(f"   Workspace ID: {workspace_id}")
                    print(f"   Connection Name: {connection_name}")
                    
                    # Verificar se Ã© um problema de permissÃ£o ou IDs invÃ¡lidos
                    try:
                        response_json = response.json()
                        if "message" in response_json:
                            print(f"   Mensagem de erro: {response_json['message']}")
                        if "data" in response_json and response_json["data"]:
                            print(f"   Dados adicionais: {response_json['data']}")
                    except:
                        pass
                
                elif response.status_code == 400:
                    print("ğŸ” ANÃLISE DO ERRO 400:")
                    if "conflicting" in response.text.lower():
                        print("   PossÃ­vel problema: Stream/connection conflitante")
                        print(f"   Stream name: {stream_name}")
                    else:
                        print("   PossÃ­vel problema: Estrutura da requisiÃ§Ã£o")
                        
        except Exception as e:
            print(f"âŒ ExceÃ§Ã£o ao criar connection para {month_name}: {str(e)}")
    
    print(f"\nğŸ“Š Resumo: {len(connections_created)} connections criadas")
    
    # EstatÃ­sticas de criaÃ§Ã£o
    created_count = len([c for c in connections_created if c.get('schedule') == 'manual'])
    existing_count = len([c for c in connections_created if c.get('schedule') == 'existing'])
    
    print(f"ğŸ†• Connections criadas: {created_count}")
    print(f"ğŸ“‹ Connections jÃ¡ existiam: {existing_count}")
    
    return connections_created

@task
def trigger_initial_sync(connections_created):
    """Dispara sincronizaÃ§Ã£o inicial para todas as connections criadas"""
    context = get_current_context()
    params = context.get("params", {})
    trigger_sync = params.get("trigger_sync", True)
    
    if not trigger_sync:
        print("â­ï¸ Sync automÃ¡tico desabilitado via parÃ¢metro 'trigger_sync': False")
        return []
    
    if not connections_created:
        print("âŒ Nenhuma connection foi criada")
        return []
    
    print(f"ğŸš€ Disparando sincronizaÃ§Ã£o inicial para {len(connections_created)} connections...")
    
    sync_results = []
    
    for connection_info in connections_created:
        connection_id = connection_info["connection_id"]
        month_name = connection_info["name"]
        
        print(f"ğŸ”„ Iniciando sync para {month_name} ({connection_id})...")
        
        try:
            # Usar endpoint correto /jobs para iniciar sync
            sync_data = {
                "connectionId": connection_id,
                "jobType": "sync"
            }
            
            response = make_api_request("POST", "/jobs", sync_data)
            
            if response.status_code in [200, 201]:
                job_info = response.json()
                job_id = job_info.get("jobId") or job_info.get("id")
                job_status = job_info.get("status", "unknown")
                print(f"âœ… Sync job criado para {month_name}: {job_id} (status: {job_status})")
                sync_results.append({
                    "connection_id": connection_id,
                    "month_name": month_name,
                    "job_id": job_id,
                    "status": "started",
                    "job_status": job_status
                })
            else:
                print(f"âŒ Erro ao iniciar sync para {month_name}: {response.status_code}")
                print(f"Resposta: {response.text}")
                sync_results.append({
                    "connection_id": connection_id,
                    "month_name": month_name,
                    "status": "failed"
                })
                
        except Exception as e:
            print(f"âŒ ExceÃ§Ã£o ao iniciar sync para {month_name}: {str(e)}")
            sync_results.append({
                "connection_id": connection_id,
                "month_name": month_name,
                "status": "error",
                "error": str(e)
            })
    
    successful_syncs = len([s for s in sync_results if s.get('status') == 'started'])
    print(f"\nğŸ‰ Resumo: {successful_syncs} sincronizaÃ§Ãµes iniciadas com sucesso!")
    
    return sync_results

# Definir e executar as tasks
with dag:
    sources_created = create_sources_task()
    connections_created = create_connections_task(sources_created)
    sync_results = trigger_initial_sync(connections_created)
    
    # Definir dependÃªncias
    sources_created >> connections_created >> sync_results